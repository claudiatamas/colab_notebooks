{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZkSM53mMjefh0Mchb5nS/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiatamas/colab_notebooks/blob/main/random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Random Forest: Diabetes Prediction***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HbXYP4-OqScQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Algorithm Theory**\n",
        "\n",
        "\n",
        "The Random Forest algorithm is an ensemble-based machine learning method used for classification, regression, and other tasks. It builds multiple decision trees and combines them to make a more robust and accurate prediction. Each tree in the forest is trained on a random subset of the training dataset, and the final prediction is determined by a weighted vote.\n",
        "\n",
        "### **Problem Description**\n",
        "We will use Random Forest to classify patients into two categories: diabetic and non-diabetic.\n",
        "\n",
        "\n",
        "\n",
        "### **Libraries Used**\n",
        "\n",
        "\n",
        "\n",
        "* **pandas** - A Python library for data manipulation and analysis. Provides fast, flexible, and expressive data structures designed to make working with relational or labeled data easy and intuitive. Supports operations like filtering, cleaning, exploring, and analyzing data.\n",
        "\n",
        "* **scikit-learn** - One of the most popular machine learning libraries in Python. Provides tools for statistical modeling, including classification, regression, clustering, and dimensionality reduction. Includes preprocessing methods, ML algorithms, and model evaluation tools.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JTgTN7uENoaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "ZxEH2IP0s-4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**\n",
        "\n",
        "The dataset **diabetes_prediction_dataset.csv** includes information about individuals with the following features:\n",
        "* **gender** - The gender of the individual\n",
        "* **age** - Age of the individual\n",
        "* **hypertension** - Whether the individual has hypertension\n",
        "* **heart_disease** - Presence or absence of heart disease\n",
        "* **smoking_history** - Smoking history of the individual\n",
        "* **BMI** - Body Mass Index, evaluating weight relative to height\n",
        "* **HbA1c_level** - Glycated hemoglobin level in the blood\n",
        "* **blood_glucose_level** - Blood sugar level\n",
        "\n",
        "The variable **diabetes** is the dependent variable, indicating whether an individual has diabetes.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ElrNaBcWt7Ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Algorithm Steps**\n",
        "\n",
        "\n",
        "1.   At this stage, the dataset is loaded from a CSV file into a pandas DataFrame for processing..\n"
      ],
      "metadata": {
        "id": "reqHT7mdvDoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded['diabetes_prediction_dataset.csv']))\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ex697QPZIsL",
        "outputId": "50a9c56f-08fa-46e4-a5bd-e5ab3526ca65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
            "0      Female  80.0             0              1           never  25.19   \n",
            "1      Female  54.0             0              0         No Info  27.32   \n",
            "2        Male  28.0             0              0           never  27.32   \n",
            "3      Female  36.0             0              0         current  23.45   \n",
            "4        Male  76.0             1              1         current  20.14   \n",
            "...       ...   ...           ...            ...             ...    ...   \n",
            "99995  Female  80.0             0              0         No Info  27.32   \n",
            "99996  Female   2.0             0              0         No Info  17.37   \n",
            "99997    Male  66.0             0              0          former  27.83   \n",
            "99998  Female  24.0             0              0           never  35.42   \n",
            "99999  Female  57.0             0              0         current  22.43   \n",
            "\n",
            "       HbA1c_level  blood_glucose_level  diabetes  \n",
            "0              6.6                  140         0  \n",
            "1              6.6                   80         0  \n",
            "2              5.7                  158         0  \n",
            "3              5.0                  155         0  \n",
            "4              4.8                  155         0  \n",
            "...            ...                  ...       ...  \n",
            "99995          6.2                   90         0  \n",
            "99996          6.5                  100         0  \n",
            "99997          5.7                  155         0  \n",
            "99998          4.0                  100         0  \n",
            "99999          6.6                   90         0  \n",
            "\n",
            "[100000 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data preprocessing – In this step, the dataset is transformed to prepare it for the Random Forest model. Categorical features are converted into a numeric format using one-hot encoding, a preprocessing technique that transforms each unique value in a categorical column into a new binary column."
      ],
      "metadata": {
        "id": "CR_9BPiIIrWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = ['gender', 'smoking_history']\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "\n",
        "\n",
        "numerical_features = X.drop(columns=categorical_features).columns\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', one_hot_encoder, categorical_features),\n",
        "        ('num', scaler, numerical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "6r1OCO-8Irz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Preparing training and test sets – These lines of code separate the features (X) and the target variable (y), and then split the data into training and test sets.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AHmErr4ovUQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('diabetes', axis=1)\n",
        "y = df['diabetes']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DoMVzhqrvX8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Training the model – Here, the Random Forest model is trained on the training dataset."
      ],
      "metadata": {
        "id": "Lgk44alNgTGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AbbAkxbUgawX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Predictions and model evaluation – After training, the model makes predictions on the test set. The accuracy and classification report are then calculated and displayed."
      ],
      "metadata": {
        "id": "Zh-16BquvdSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f'Acuratețea modelului Random Forest: {accuracy_rf}')\n",
        "\n",
        "report_rf = classification_report(y_test, y_pred_rf)\n",
        "print(report_rf)"
      ],
      "metadata": {
        "id": "uev4oqM9vgKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Visualizing results – Finally, a table is created to compare the actual data with the model's predicted values."
      ],
      "metadata": {
        "id": "iYBepySOf2dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_rf = pd.DataFrame({'Real Data': y_test, 'Predicted Data': y_pred_rf})\n",
        "print(test_results_rf.head(51))"
      ],
      "metadata": {
        "id": "IMzaBTHjf3ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Splitting:**\n",
        "The dataset will be split into 80% for training and 20% for testing."
      ],
      "metadata": {
        "id": "Jk4sGLumuo7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Conclusions**\n",
        "\n",
        "**High Accuracy**: The model achieves an overall accuracy of approximately 97%, indicating strong performance in correctly classifying cases as diabetic or non-diabetic.\n",
        "\n",
        "***Class 0 (Non-diabetic) Classification:***:\n",
        "\n",
        "1. Precision: 97% precision for class 0 suggests that 97% of the model’s predictions for non-diabetics are correct.\n",
        "2. Recall: 100% recall indicates that the model correctly identified all actual non-diabetic cases in the test set.\n",
        "3. F1-Score: An F1-score of 98% for class 0 is very high, reflecting a good balance between precision and recall.\n",
        "\n",
        "***Class 1 (Diabetic) Classification:***:\n",
        "1. Precision: 95% precision for class 1 is very good, indicating that almost all of the model’s predictions for diabetics are correct.\n",
        "2. Recall: However, a recall of only 69% for class 1 suggests the model missed several actual diabetic cases in the test set.\n",
        "2. F1-Score: An F1-score of 80% for class 1 is significantly lower than that for class 0 due to the lower recall."
      ],
      "metadata": {
        "id": "hLRWqU_mDXKk"
      }
    }
  ]
}